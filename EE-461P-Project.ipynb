{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting pneumonia using chest x-rays\n",
    "\n",
    "### To Do List\n",
    "\n",
    "#### Research:\n",
    "* CNNs\n",
    "    * How do they work?\n",
    "    * Idea of transfer learning\n",
    "* Unique CNN implementations: AlexNet, CapsNet, GNN\n",
    "    * What is unique about each of these implementations?\n",
    "    \n",
    "#### Implementation:\n",
    "* Basic CNNs (PyTorch, tensorflow, keras)\n",
    "* Transfer learning example\n",
    "* Unique CNN implementations\n",
    "* Understanding what the CNN found important (https://github.com/albermax/innvestigate)\n",
    "\n",
    "#### Blog:\n",
    "* Choosing a service (Medium, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks (CNNs)\n",
    "\n",
    "CNNs are used for classifaction and computer vision. They are made up of three types of layers: convolutional, pooling, and fully-connected (FC). The first layer is a convolutional layer, and the last layer is the only fully-connected layer. The layers in between may be a mix of convolutional and pooling layers [1]. \n",
    "\n",
    "##### Convolutional Layers [1]\n",
    "Convolutiuonal layers have an input, a filter (AKA kernel or feature detector), and a feature map. The feature detector is typically a 2D array of weights, which is applied to a subsection of the input. The dot product between this subsection and the kernel is then calculated. The filter then shifts by a stride, and performs the dot product operation once more, repeating this process until it has covered the entire input. The resulting array of outputs is called the feature map.\n",
    "\n",
    "Some hyperparameters that can be adjusted in the convolutional layer are number of filters, stride, and zero padding. Number of filters affects the depth of the feature map (e.g. three filters results in a depth three feature map). Stride is the number of pixels the kernel moves after each dot product calculation. Zero padding refers to the amount of padding added to an input (eg. an image) to ensure that the filter fits the image.\n",
    "\n",
    "After each convolution, the CNN applies a ReLU to introduce nonlinearities into the network, ensuring that the model is a universal approximator.\n",
    "\n",
    "##### Pooling Layers [1]\n",
    "Similar to a convolutional layer, except the filter does not use weights. Instead it implements a specific type of pooling: max pooling or average pooling. Max pooling is when the filter selects the pixel of maximum value to send to the output array. Average pooling is when the filter calculates the average value in the receptive field (the values that the filter can see).\n",
    "\n",
    "More information is lost in pooling layers, but they \"reduce complexity, improve efficiency, and limit risk of overfitting\".\n",
    "\n",
    "##### Fully-Connected Layer [1]\n",
    "Usually uses a softmax activation function to make the final classification prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Neural Networks (RNNs) [5]\n",
    "\n",
    "RNNs are neural networks that include residual blocks. In residual blocks, layers feed directly into layers 2-3 layers deeper, while also still feeding into the next layer. These connections to deeper layers are called skip connections or residual connections. \n",
    "\n",
    "Generally the layers a NN solve for the true distribution H(x). However, the layers of a residual block solve for the residual! R(x) = Output - Input = H(x) - x => H(x) = R(x) + x. RNNs can also help with the problem of vanishing gradient by using skip connections to back propoagate larger gradients to earlier layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning\n",
    "\n",
    "Briefly introduced in class was the idea of transfer learning, whereby a previously trained neural network is used in a new problem. The ResNet50 network from PyTorch is a pretrained, RNN with 50 layers. ResNet50 is trained on images, and as such, early layers \"learned\" basic image features such as lines and shapes that can be used in any image classification problem. This saves an enormous amount of time and compute power, since those layers no longer need to be trained for new problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic CNN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to run with Python 3.6, Tensorflow 1.15, and Keras 2.2.4 for iNNvestigate\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 # https://pypi.org/project/opencv-python/\n",
    "import seaborn as sns\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.optimizers import SGD\n",
    "import os\n",
    "\n",
    "import tensorflow\n",
    "import keras\n",
    "\n",
    "print(tensorflow.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['PNEUMONIA', 'NORMAL']\n",
    "img_size = 150\n",
    "def get_training_data(data_dir):\n",
    "    data = []\n",
    "    for label in labels:\n",
    "        path = os.path.join(data_dir, label)\n",
    "        class_num = labels.index(label)\n",
    "        for img in os.listdir(path):\n",
    "            if img == '.DS_Store' :\n",
    "                continue\n",
    "            try:\n",
    "                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                resized_arr = cv2.resize(img_arr, (img_size, img_size))\n",
    "                data.append([resized_arr, class_num])\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print (os.path.join(path, img))\n",
    "                \n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = get_training_data('./chest_xray/train')\n",
    "test = get_training_data('./chest_xray/test')\n",
    "val = get_training_data('./chest_xray/val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA (Exploratory Data Analysis) [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "a1 = fig.add_subplot(1,2,1)\n",
    "plt.imshow(train[0][0], cmap='gray')\n",
    "a1.set_title(labels[train[0][1]])\n",
    "a1.set_xticks([])\n",
    "a1.set_yticks([])\n",
    "\n",
    "a2 = fig.add_subplot(1, 2, 2)\n",
    "plt.imshow(train[-1][0], cmap='gray')\n",
    "a2.set_title(labels[train[-1][1]])\n",
    "a2.set_xticks([])\n",
    "a2.set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in train:\n",
    "    if(i[1] == 0):\n",
    "        l.append('Pneumonia')\n",
    "    else:\n",
    "        l.append('Normal')\n",
    "        \n",
    "sns.set_style('darkgrid')\n",
    "sns.countplot(x=l)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic CNN Implementation [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for feature, label in train:\n",
    "    x_train.append(feature)\n",
    "    y_train.append(label)\n",
    "    \n",
    "for feature, label in val:\n",
    "    x_train.append(feature)\n",
    "    y_train.append(label)\n",
    "    \n",
    "for feature, label in test:\n",
    "    x_test.append(feature)\n",
    "    y_test.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "\n",
    "x_train = np.array(x_train) / 255\n",
    "x_test = np.array(x_test) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizing Data For CNN\n",
    "\n",
    "x_train = x_train.reshape(-1, img_size, img_size, 1)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_test = x_test.reshape(-1, img_size, img_size, 1)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up StratifiedKFold for cross validation\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "sfk = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation (Grayscales, Horizontal Flips, Vertical Flips, Random Crops, Color Jitters, Translations, Rotations, ...)\n",
    "# Slightly alter the training data to increase the number of training examples and prevent overfitting\n",
    "\n",
    "datagen = ImageDataGenerator(featurewise_center=False,\n",
    "                             samplewise_center=False,\n",
    "                             featurewise_std_normalization=False,\n",
    "                             samplewise_std_normalization=False,\n",
    "                             zca_whitening=False,\n",
    "                             rotation_range=30,\n",
    "                             zoom_range=0.2,\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             horizontal_flip=True,\n",
    "                             vertical_flip=False)\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://faroit.com/keras-docs/2.1.2/models/about-keras-models/\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), strides=1, padding='same', activation='relu', input_shape=(150, 150, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2, 2), strides=2, padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2, 2), strides=2, padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2, 2), strides=2, padding='same'))\n",
    "model.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(256 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 128 , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units = 1 , activation = 'sigmoid'))\n",
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer = sgd , loss = 'binary_crossentropy' , metrics = ['accuracy'])\n",
    "model.summary()\n",
    "model.save_weights('./models/keras-untrained.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=2, verbose=1, factor=0.3, min_lr=0.000001)\n",
    "\n",
    "for train_index, val_index in sfk.split(x_train, y_train):\n",
    "    # Reset weights\n",
    "    model.load_weights('./models/keras-untrained.h5')\n",
    "    \n",
    "    # Reset learning rate if reduced by callback\n",
    "    sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer = sgd , loss = 'binary_crossentropy' , metrics = ['accuracy'])\n",
    "    \n",
    "    X_train, X_val = x_train[train_index], x_train[val_index]\n",
    "    Y_train, Y_val = y_train[train_index], y_train[val_index]\n",
    "    model.fit_generator(datagen.flow(X_train, Y_train, batch_size=32), epochs=10, steps_per_epoch = len(X_train) / 32,\n",
    "                   validation_data=[X_val, Y_val], callbacks=[learning_rate_reduction], shuffle=True)\n",
    "    \n",
    "    model.save(f'./models/keras-cnn-k{k}.h5')\n",
    "    k = k + 1\n",
    "    \n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for k in range(1,6):\n",
    "    model = load_model(f'./models/keras-cnn-k{k}.h5')\n",
    "    print(f'----- MODEL {k} -----')\n",
    "    acc = model.evaluate(x_test, y_test)[1]\n",
    "    total += acc\n",
    "    print(\"Accuracy of the model is - \" , acc*100 , \"%\")\n",
    "    print()\n",
    "    \n",
    "print(f'Mean: {total / 5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the best model obtained during cross validation and observe the metrics\n",
    "\n",
    "model = load_model(f'./models/keras-cnn-k{1}.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict_proba(x_test)\n",
    "y_pred = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(fpr, tpr, label=f'AUC: {roc_auc_score(y_test, y_prob):.2f}')\n",
    "plt.axis([0,1,0,1])\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.legend(loc='lower right', prop={'size': 20})\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(matrix)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iNNvestigate [7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import innvestigate\n",
    "import innvestigate.applications.imagenet\n",
    "import innvestigate.layers as ilayers\n",
    "import innvestigate.utils as iutils\n",
    "import innvestigate.utils.keras as kutils\n",
    "import innvestigate.utils.keras.checks as kchecks\n",
    "import innvestigate.utils.keras.graph as kgraph\n",
    "\n",
    "innvestigate.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [x_test[i] for i in range(-3, 3)]\n",
    "labels = ['NORMAL' if y_test[i] else 'PNEUMONIA' for i in range(-3, 3)]\n",
    "predictions = [model.predict(x.reshape(1, 150, 150, 1))[0][0] for x in images]\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(20,10))\n",
    "\n",
    "for ax, im, l, p in zip(np.append(axs[0], axs[1]), images, labels, predictions):\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    ax.set_title(f'True: {l} // Predicted: {p:.2f} ')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an analyzer\n",
    "gradient_analyzer = innvestigate.create_analyzer('guided_backprop', model)\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(20,10))\n",
    "\n",
    "for ax, im, l, p in zip(np.append(axs[0], axs[1]), images, labels, predictions):\n",
    "    \n",
    "    # Applying the analyzer\n",
    "    analysis = gradient_analyzer.analyze(im.reshape(1, 150, 150, 1))\n",
    "    \n",
    "    ax.imshow(analysis.squeeze(), cmap='gray')\n",
    "    ax.set_title(f'True: {l} // Predicted: {p:.2f} ')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an analyzer\n",
    "dt_analyzer = innvestigate.create_analyzer('deep_taylor', model)\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(20,10))\n",
    "\n",
    "for ax, im, l, p in zip(np.append(axs[0], axs[1]), images, labels, predictions):\n",
    "    \n",
    "    # Applying the analyzer\n",
    "    a = dt_analyzer.analyze(im.reshape(1, 150, 150, 1))\n",
    "\n",
    "    # Displaying the gradient\n",
    "    a = a.sum(axis=np.argmax(np.asarray(a.shape) == 3))\n",
    "    a /= np.max(np.abs(a))\n",
    "    # Plot\n",
    "    ax.imshow(a, cmap=\"seismic\", clim=(-0.3, 0.3))\n",
    "    ax.set_title(f'True: {l} // Predicted: {p:.2f} ')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning with ResNet [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as tt\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageFolder('./chest_xray/train',\n",
    "                         transform=tt.Compose([tt.Resize(255),\n",
    "                                               tt.CenterCrop(224),\n",
    "                                               tt.RandomHorizontalFlip(),\n",
    "                                               tt.RandomRotation(10),\n",
    "                                               tt.RandomGrayscale(),\n",
    "                                               tt.RandomAffine(translate=(0.05,0.05), degrees=0),\n",
    "                                               tt.ToTensor()\n",
    "                                              ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = round(len(dataset)*0.7)\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(dl):\n",
    "    for images, labels in dl:\n",
    "        fig, ax = plt.subplots(figsize=(12, 12))\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.imshow(make_grid(images[0:60], nrow=10).permute(1, 2, 0))\n",
    "        break\n",
    "        \n",
    "show_batch(train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds==labels).item() / len(preds)), preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Model [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PneumoniaModelBase(nn.Module):\n",
    "    \n",
    "    def training_step(self, batch, weight):\n",
    "        images, labels = batch\n",
    "        out = self(images)\n",
    "        loss = F.cross_entropy(out, labels, weight=weight)\n",
    "        acc, preds = accuracy(out, labels)\n",
    "        \n",
    "        return {'train_loss': loss, 'train_acc': acc}\n",
    "    \n",
    "    def train_epoch_end(self, outputs):\n",
    "        batch_losses = [x['train_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()\n",
    "        batch_accs = [x['train_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()\n",
    "        \n",
    "        return {'train_loss': epoch_loss.item(), 'train_acc': epoch_acc.item()}\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images,labels = batch\n",
    "        out = self(images)\n",
    "        loss = F.cross_entropy(out, labels)\n",
    "        acc,preds = accuracy(out, labels)\n",
    "        \n",
    "        return {'val_loss': loss.detach(), 'val_acc':acc.detach(), \n",
    "                'preds':preds.detach(), 'labels':labels.detach()}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()     \n",
    "        \n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, train_result, val_result):\n",
    "        print('Epoch [{}], train_loss: {:.4f}, train_acc: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}'.\n",
    "              format(epoch+1, train_result['train_loss'], train_result['train_acc'],\n",
    "                     val_result['val_loss'], val_result['val_acc']))\n",
    "        \n",
    "    def test_prediction(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()\n",
    "        batch_preds = [pred for x in outputs for pred in x['preds'].tolist()] \n",
    "        batch_labels = [lab for x in outputs for lab in x['labels'].tolist()]  \n",
    "        \n",
    "        return {'test_loss': epoch_loss.item(), 'test_acc': epoch_acc.item(),\n",
    "                'test_preds': batch_preds, 'test_labels': batch_labels}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PneumoniaResnet(PneumoniaModelBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = models.resnet50(pretrained=True)\n",
    "        for param in self.network.fc.parameters():\n",
    "            param.require_grad = False\n",
    "        num_features = self.network.fc.in_features\n",
    "        self.network.fc = nn.Linear(num_features, 2)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "    \n",
    "def fit(epochs, lr, model, train_loader, val_loader, weight, weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
    "    torch.cuda.empty_cache()\n",
    "    history = {}\n",
    "    \n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    best_loss = 1\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "        train_outputs = []\n",
    "        lrs = []\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            outputs = model.training_step(batch, weight)\n",
    "            loss = outputs['train_loss']\n",
    "            train_outputs.append(outputs)\n",
    "            \n",
    "            train_results = model.train_epoch_end(train_outputs)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        val_results = evaluate(model, val_loader)\n",
    "        if val_results['val_loss'] < best_loss and epoch + 1 > 15:\n",
    "            best_loss = min(best_loss, val_results['val_loss'])\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "        model.epoch_end(epoch, train_results, val_results)\n",
    "        \n",
    "        to_add = {'train_loss': train_results['train_loss'],\n",
    "                  'train_acc': train_results['train_acc'],\n",
    "                 'val_loss': val_results['val_loss'],\n",
    "                  'val_acc': val_results['val_acc'], 'lrs':lrs}\n",
    "        \n",
    "        for key,val in to_add.items():\n",
    "            if key in history:\n",
    "                history[key].append(val)\n",
    "            else:\n",
    "                history[key] = [val]\n",
    "                \n",
    "        model.load_state_dict(best_model_wts)\n",
    "        \n",
    "        return history, optimizer, best_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Model [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "val_dl = DeviceDataLoader(val_dl, device)\n",
    "\n",
    "model = to_device(PneumoniaResnet(), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "lr = 0.0001\n",
    "grad_clip = None\n",
    "weight_decay = 1e-4\n",
    "opt_func = torch.optim.Adam\n",
    "weight = torch.FloatTensor([3876/1342+3876, 1342/(1342+3876)]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Had to run this on Kaggle since my GPU did not have enough memory\n",
    "\n",
    "# history, optimizer, best_loss = fit(epochs, lr, model, train_dl, val_dl, weight,\n",
    "#                                     grad_clip=grad_clip,\n",
    "#                                     weight_decay=weight_decay,\n",
    "#                                     opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = checkpoint['model']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    for parameter in model.parameters():\n",
    "        parameter.requires_grad = False\n",
    "\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "model = load_checkpoint('./models/PneumoniaResnet.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test_predict(model, test_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in test_loader] \n",
    "    results = model.test_prediction(outputs)                          \n",
    "    print('test_loss: {:.4f}, test_acc: {:.4f}'\n",
    "          .format(results['test_loss'], results['test_acc']))\n",
    "    \n",
    "    return results['test_preds'], results['test_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ImageFolder('./chest_xray/test', \n",
    "                           transform=tt.Compose([tt.Resize(255),\n",
    "                                                 tt.CenterCrop(224),                                                              \n",
    "                                                 tt.ToTensor()\n",
    "                                                ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataLoader(test_dataset, batch_size=256)\n",
    "# test_dl = DeviceDataLoader(test_dl, device)\n",
    "preds,labels = test_predict(model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(labels, preds)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, figsize=(12,8), cmap=plt.cm.Blues)\n",
    "plt.xticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\n",
    "plt.yticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\n",
    "plt.xlabel('Predicted Label', fontsize=18)\n",
    "plt.ylabel('True Label', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with FastAI [6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastai.data.all import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './chest_xray/train'\n",
    "fnames = get_image_files(path)\n",
    "\n",
    "def label_func(x): return x.parent.name\n",
    "\n",
    "dls = ImageDataLoaders.from_path_func(path, fnames, label_func, item_tfms=Resize(224), bs=16, num_workers=0,\n",
    "                                      batch_tfms=aug_transforms(pad_mode='zeros', max_warp=0, max_zoom=1)) \n",
    "dls.show_batch(max_n=9, figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet34, pretrained=True)\n",
    "\n",
    "learn.fit_one_cycle(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CapsNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is starting point I attempted, for text data not images\n",
    "https://www.kaggle.com/fizzbuzz/beginner-s-guide-to-capsule-networks\n",
    "\n",
    "#Another starting point attempt\n",
    "https://www.analyticsvidhya.com/blog/2018/04/essentials-of-deep-learning-getting-to-know-capsulenets/\n",
    "    \n",
    "#Here is a good library I fiddled with, should be possible to use with our dataset\n",
    "https://github.com/naturomics/CapsLayer\n",
    "    \n",
    "#My next step was going to be this video + the code in description\n",
    "https://www.youtube.com/watch?v=2Kawrd5szHE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# trying from .. https://www.kaggle.com/rodcardoso92/using-vgg-capsnet-to-diagnose-pneumonia/comments\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras import backend as K\n",
    "from keras import activations\n",
    "from keras import utils\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import *\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.optimizers import RMSprop, Adam, SGD, Nadam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from keras import regularizers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "IMG_SIZE = 299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataGenerator(train_batch, val_batch, IMG_SIZE):\n",
    "    datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                 rescale=1./255,\n",
    "                                 rotation_range=10,\n",
    "                                 horizontal_flip=True,\n",
    "                                 vertical_flip=True)\n",
    "\n",
    "    datagen.mean=np.array([103.939, 116.779, 123.68],dtype=np.float32).reshape(1,1,3)\n",
    "\n",
    "    train_gen = datagen.flow_from_directory('./chest_xray/train/',\n",
    "                                            target_size=(IMG_SIZE, IMG_SIZE),\n",
    "                                            color_mode='rgb', \n",
    "                                            class_mode='categorical',\n",
    "                                            batch_size=train_batch)\n",
    "\n",
    "    val_gen = datagen.flow_from_directory('./chest_xray/val/', \n",
    "                                          target_size=(IMG_SIZE, IMG_SIZE),\n",
    "                                          color_mode='rgb', \n",
    "                                          class_mode='categorical',\n",
    "                                          batch_size=val_batch)\n",
    "\n",
    "    datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                 rescale=1./255)\n",
    "    \n",
    "    datagen.mean=np.array([103.939, 116.779, 123.68],dtype=np.float32).reshape(1,1,3)\n",
    "\n",
    "    test_gen = datagen.flow_from_directory('./chest_xray/test/', \n",
    "                                           target_size=(IMG_SIZE, IMG_SIZE),\n",
    "                                           color_mode='rgb', \n",
    "                                           class_mode='categorical',\n",
    "                                           shuffle=False)\n",
    "    \n",
    "    return train_gen, val_gen, test_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(x, axis=-1):\n",
    "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True) + K.epsilon()\n",
    "    scale = K.sqrt(s_squared_norm) / (0.5 + s_squared_norm)\n",
    "    return scale * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, axis=-1):\n",
    "    ex = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
    "    return ex / K.sum(ex, axis=axis, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def margin_loss(y_true, y_pred):\n",
    "    lamb, margin = 0.5, 0.1 #default lambda 0.5 - but test with lambda with 0.9 - 0.1\n",
    "    return K.sum(y_true * K.square(K.relu(1 - margin - y_pred)) + lamb * (\n",
    "        1 - y_true) * K.square(K.relu(y_pred - margin)), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Capsule(Layer):\n",
    "    \"\"\"A Capsule Implement with Pure Keras\n",
    "    There are two vesions of Capsule.\n",
    "    One is like dense layer (for the fixed-shape input),\n",
    "    and the other is like timedistributed dense (for various length input).\n",
    "\n",
    "    The input shape of Capsule must be (batch_size,\n",
    "                                        input_num_capsule,\n",
    "                                        input_dim_capsule\n",
    "                                       )\n",
    "    and the output shape is (batch_size,\n",
    "                             num_capsule,\n",
    "                             dim_capsule\n",
    "                            )\n",
    "\n",
    "    Capsule Implement is from https://github.com/bojone/Capsule/\n",
    "    Capsule Paper: https://arxiv.org/abs/1710.09829\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_capsule,\n",
    "                 dim_capsule,\n",
    "                 routings=3, # Test number of routing with (1, 2, 3, 4) - Default = 3\n",
    "                 share_weights=True,\n",
    "                 activation='squash',\n",
    "                 **kwargs):\n",
    "        super(Capsule, self).__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "        self.share_weights = share_weights\n",
    "        if activation == 'squash':\n",
    "            self.activation = squash\n",
    "        else:\n",
    "            self.activation = activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_dim_capsule = input_shape[-1]\n",
    "        if self.share_weights:\n",
    "            self.kernel = self.add_weight(\n",
    "                name='capsule_kernel',\n",
    "                shape=(1, input_dim_capsule,\n",
    "                       self.num_capsule * self.dim_capsule),\n",
    "                initializer='glorot_uniform',\n",
    "                trainable=True)\n",
    "        else:\n",
    "            input_num_capsule = input_shape[-2]\n",
    "            self.kernel = self.add_weight(\n",
    "                name='capsule_kernel',\n",
    "                shape=(input_num_capsule, input_dim_capsule,\n",
    "                       self.num_capsule * self.dim_capsule),\n",
    "                initializer='glorot_uniform',\n",
    "                trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"Following the routing algorithm from Hinton's paper,\n",
    "        but replace b = b + <u,v> with b = <u,v>.\n",
    "\n",
    "        This change can improve the feature representation of Capsule.\n",
    "\n",
    "        However, you can replace\n",
    "            b = K.batch_dot(outputs, hat_inputs, [2, 3])\n",
    "        with\n",
    "            b += K.batch_dot(outputs, hat_inputs, [2, 3])\n",
    "        to realize a standard routing.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.share_weights:\n",
    "            hat_inputs = K.conv1d(inputs, self.kernel)\n",
    "        else:\n",
    "            hat_inputs = K.local_conv1d(inputs, self.kernel, [1], [1])\n",
    "\n",
    "        batch_size = K.shape(inputs)[0]\n",
    "        input_num_capsule = K.shape(inputs)[1]\n",
    "        hat_inputs = K.reshape(hat_inputs,\n",
    "                               (batch_size, input_num_capsule,\n",
    "                                self.num_capsule, self.dim_capsule))\n",
    "        hat_inputs = K.permute_dimensions(hat_inputs, (0, 2, 1, 3))\n",
    "\n",
    "        b = K.zeros_like(hat_inputs[:, :, :, 0])\n",
    "        for i in range(self.routings):\n",
    "            c = softmax(b, 1)\n",
    "            o = self.activation(K.batch_dot(c, hat_inputs, [2, 2]))\n",
    "            if i < self.routings - 1:\n",
    "                b = K.batch_dot(o, hat_inputs, [2, 3])\n",
    "                if K.backend() == 'theano':\n",
    "                    o = K.sum(o, axis=1)\n",
    "\n",
    "        return o\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.num_capsule, self.dim_capsule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batch = 32\n",
    "val_batch = 1\n",
    "\n",
    "train, val, test = DataGenerator(train_batch, val_batch, IMG_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\simoni\\Anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\simoni\\Anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\simoni\\Anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\simoni\\Anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\simoni\\Anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\simoni\\Anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\simoni\\Anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\simoni\\Anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\simoni\\Anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\simoni\\Anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 299, 299, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 299, 299, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 299, 299, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 149, 149, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 149, 149, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 149, 149, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 74, 74, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 74, 74, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 74, 74, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 74, 74, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 37, 37, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 37, 37, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 37, 37, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 37, 37, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "<keras.engine.input_layer.InputLayer object at 0x000001331748D668> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001331748D630> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001331748DBE0> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x0000013317488C18> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000133174A0A90> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000133174A63C8> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x00000133174AA1D0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000133174B07F0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000133174B8908> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000133174BD668> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x00000133174CA588> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000133174CE668> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000133174D57F0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000133174DD710> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x00000133174E6550> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000133174EDEB8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000133174F4710> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000133174F8470> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x00000133175054A8> False\n",
      "WARNING:tensorflow:From C:\\Users\\simoni\\Anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\simoni\\Anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 299, 299, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 299, 299, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 299, 299, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 149, 149, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 149, 149, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 149, 149, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 74, 74, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 74, 74, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 74, 74, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 74, 74, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 37, 37, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 37, 37, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 37, 37, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 37, 37, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 8194      \n",
      "=================================================================\n",
      "Total params: 16,824,130\n",
      "Trainable params: 2,109,442\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\simoni\\Anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\simoni\\Anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\simoni\\Anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\simoni\\Anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\simoni\\Anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/1\n",
      "326/326 [==============================] - 5934s 18s/step - loss: 0.3208 - acc: 0.8552 - val_loss: 0.8707 - val_acc: 0.6250\n",
      "\n",
      "\n",
      "================================\n",
      "\n",
      "\n",
      "Loss: 0.43730260527286774\n",
      "Accuracy: 78.85 %\n",
      "\n",
      "\n",
      "================================\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "326/326 [==============================] - 5902s 18s/step - loss: 0.1876 - acc: 0.9274 - val_loss: 0.5644 - val_acc: 0.7500\n",
      "Epoch 2/10\n",
      "326/326 [==============================] - 6118s 19s/step - loss: 0.1228 - acc: 0.9523 - val_loss: 0.9376 - val_acc: 0.6250\n",
      "Epoch 3/10\n",
      "326/326 [==============================] - 6147s 19s/step - loss: 0.1023 - acc: 0.9634 - val_loss: 0.5009 - val_acc: 0.8125\n",
      "Epoch 4/10\n",
      "326/326 [==============================] - 6116s 19s/step - loss: 0.0934 - acc: 0.9659 - val_loss: 0.9128 - val_acc: 0.6250\n",
      "Epoch 5/10\n",
      "326/326 [==============================] - 6082s 19s/step - loss: 0.0816 - acc: 0.9711 - val_loss: 0.5537 - val_acc: 0.6875\n",
      "Epoch 6/10\n",
      "326/326 [==============================] - 6093s 19s/step - loss: 0.0797 - acc: 0.9694 - val_loss: 0.3339 - val_acc: 0.8750\n",
      "Epoch 7/10\n",
      "326/326 [==============================] - 6328s 19s/step - loss: 0.0740 - acc: 0.9734 - val_loss: 0.4685 - val_acc: 0.7500\n",
      "Epoch 8/10\n",
      "326/326 [==============================] - 6041s 19s/step - loss: 0.0700 - acc: 0.9734 - val_loss: 0.0908 - val_acc: 0.9375\n",
      "Epoch 9/10\n",
      "326/326 [==============================] - 6110s 19s/step - loss: 0.0671 - acc: 0.9757 - val_loss: 0.6284 - val_acc: 0.6250\n",
      "Epoch 10/10\n",
      "326/326 [==============================] - 6101s 19s/step - loss: 0.0621 - acc: 0.9758 - val_loss: 0.2072 - val_acc: 0.8750\n",
      "\n",
      "\n",
      "================================\n",
      "\n",
      "\n",
      "Loss: 0.26902948926465636\n",
      "Accuracy: 89.58 %\n",
      "\n",
      "\n",
      "================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_image = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "# A InceptionResNetV2 Conv2D model\n",
    "base_model = VGG16(include_top=False, weights='imagenet', input_tensor=input_image)\n",
    "\n",
    "base_model.summary()\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    print(layer, layer.trainable)\n",
    "    \n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(4096, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input_image, outputs=output)\n",
    "\n",
    "model.summary()\n",
    "lr=1e-4\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=lr), metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(train,\n",
    "                    epochs=1,\n",
    "                    validation_data=val, \n",
    "                    validation_steps = len(val.classes)//val_batch,\n",
    "                    steps_per_epoch=(len(train.classes)//train_batch) * 2) \n",
    "    \n",
    "loss, acc = model.evaluate_generator(test, len(test))\n",
    "\n",
    "print (\"\\n\\n================================\\n\\n\")\n",
    "print (\"Loss: {}\".format(loss))\n",
    "print (\"Accuracy: {0:.2f} %\".format(acc * 100))\n",
    "print (\"\\n\\n================================\\n\\n\")\n",
    "\n",
    "test.reset()\n",
    "\n",
    "for i, layer in enumerate(model.layers):\n",
    "    if i < 15:\n",
    "        layer.trainable = False\n",
    "    else:\n",
    "        layer.trainable = True\n",
    "        \n",
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=lr, momentum=0.9), metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(train,\n",
    "                    epochs=10,\n",
    "                    validation_data=val, \n",
    "                    validation_steps = len(val.classes)//val_batch,\n",
    "                    steps_per_epoch=(len(train.classes)//train_batch) * 2) \n",
    "    \n",
    "loss, acc = model.evaluate_generator(test, len(test))\n",
    "\n",
    "print (\"\\n\\n================================\\n\\n\")\n",
    "print (\"Loss: {}\".format(loss))\n",
    "print (\"Accuracy: {0:.2f} %\".format(acc * 100))\n",
    "print (\"\\n\\n================================\\n\\n\")\n",
    "\n",
    "test.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 299, 299, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 299, 299, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 299, 299, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 149, 149, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 149, 149, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 149, 149, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 74, 74, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 74, 74, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 74, 74, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 74, 74, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 37, 37, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 37, 37, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 37, 37, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 37, 37, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 1, 1, 256)         10617088  \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "capsule_1 (Capsule)          (None, 2, 16)             8192      \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 25,339,968\n",
      "Trainable params: 17,704,704\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "163/163 [==============================] - 3321s 20s/step - loss: 0.0353 - acc: 0.9507 - val_loss: 0.2223 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.22230, saving model to weights.h5\n",
      "Epoch 2/100\n",
      "163/163 [==============================] - 3320s 20s/step - loss: 0.0192 - acc: 0.9726 - val_loss: 0.2680 - val_acc: 0.6875\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.22230\n",
      "Epoch 3/100\n",
      "163/163 [==============================] - 3024s 19s/step - loss: 0.0161 - acc: 0.9780 - val_loss: 0.4282 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.22230\n",
      "Epoch 4/100\n",
      "163/163 [==============================] - 3250s 20s/step - loss: 0.0159 - acc: 0.9770 - val_loss: 0.1791 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.22230 to 0.17910, saving model to weights.h5\n",
      "Epoch 5/100\n",
      "163/163 [==============================] - 2828s 17s/step - loss: 0.0153 - acc: 0.9781 - val_loss: 0.1134 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.17910 to 0.11339, saving model to weights.h5\n",
      "Epoch 6/100\n",
      "163/163 [==============================] - 2830s 17s/step - loss: 0.0140 - acc: 0.9808 - val_loss: 0.1746 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.11339\n",
      "Epoch 7/100\n",
      "163/163 [==============================] - 3211s 20s/step - loss: 0.0146 - acc: 0.9793 - val_loss: 0.3346 - val_acc: 0.6875\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.11339\n",
      "Epoch 8/100\n",
      "163/163 [==============================] - 3437s 21s/step - loss: 0.0178 - acc: 0.9760 - val_loss: 0.1635 - val_acc: 0.6875\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.11339\n",
      "Epoch 9/100\n",
      "163/163 [==============================] - 3329s 20s/step - loss: 0.0133 - acc: 0.9816 - val_loss: 0.0643 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.11339 to 0.06433, saving model to weights.h5\n",
      "Epoch 10/100\n",
      "163/163 [==============================] - 3257s 20s/step - loss: 0.0089 - acc: 0.9872 - val_loss: 0.0959 - val_acc: 0.8125\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06433\n",
      "Epoch 11/100\n",
      "163/163 [==============================] - 2994s 18s/step - loss: 0.0129 - acc: 0.9826 - val_loss: 0.1748 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.06433\n",
      "Epoch 12/100\n",
      "163/163 [==============================] - 2099s 13s/step - loss: 0.0131 - acc: 0.9827 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.06433 to 0.00487, saving model to weights.h5\n",
      "Epoch 13/100\n",
      "163/163 [==============================] - 2100s 13s/step - loss: 0.0115 - acc: 0.9845 - val_loss: 0.0648 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00487\n",
      "Epoch 14/100\n",
      "163/163 [==============================] - 2097s 13s/step - loss: 0.0145 - acc: 0.9804 - val_loss: 0.1123 - val_acc: 0.8125\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00487\n",
      "Epoch 15/100\n",
      "163/163 [==============================] - 2099s 13s/step - loss: 0.0120 - acc: 0.9843 - val_loss: 0.0812 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00487\n",
      "Epoch 16/100\n",
      "163/163 [==============================] - 2113s 13s/step - loss: 0.0101 - acc: 0.9854 - val_loss: 0.1201 - val_acc: 0.8125\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00487\n",
      "Epoch 17/100\n",
      "163/163 [==============================] - 2108s 13s/step - loss: 0.0090 - acc: 0.9872 - val_loss: 0.0618 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00487\n",
      "Epoch 18/100\n",
      "163/163 [==============================] - 2099s 13s/step - loss: 0.0082 - acc: 0.9889 - val_loss: 0.0178 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00487\n",
      "Epoch 19/100\n",
      "163/163 [==============================] - 2100s 13s/step - loss: 0.0095 - acc: 0.9877 - val_loss: 0.0451 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00487\n",
      "Epoch 20/100\n",
      "163/163 [==============================] - 2098s 13s/step - loss: 0.0089 - acc: 0.9870 - val_loss: 0.0366 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00487\n",
      "Epoch 21/100\n",
      "163/163 [==============================] - 2096s 13s/step - loss: 0.0092 - acc: 0.9877 - val_loss: 0.0803 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00487\n",
      "Epoch 22/100\n",
      "163/163 [==============================] - 2106s 13s/step - loss: 0.0089 - acc: 0.9891 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00487 to 0.00182, saving model to weights.h5\n",
      "Epoch 23/100\n",
      "163/163 [==============================] - 2097s 13s/step - loss: 0.0080 - acc: 0.9891 - val_loss: 0.0611 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00182\n",
      "Epoch 24/100\n",
      "163/163 [==============================] - 2097s 13s/step - loss: 0.0088 - acc: 0.9885 - val_loss: 5.8502e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00182 to 0.00059, saving model to weights.h5\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 3340s 20s/step - loss: 0.0100 - acc: 0.9868 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00059\n",
      "Epoch 26/100\n",
      "163/163 [==============================] - 3817s 23s/step - loss: 0.0071 - acc: 0.9908 - val_loss: 0.0402 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00059\n",
      "Epoch 27/100\n",
      "163/163 [==============================] - 4428s 27s/step - loss: 0.0065 - acc: 0.9921 - val_loss: 0.0273 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00059\n",
      "Epoch 28/100\n",
      "163/163 [==============================] - 3272s 20s/step - loss: 0.0067 - acc: 0.9900 - val_loss: 0.0559 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00059\n",
      "Epoch 29/100\n",
      "163/163 [==============================] - 3521s 22s/step - loss: 0.0076 - acc: 0.9898 - val_loss: 0.0218 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00059\n",
      "Epoch 30/100\n",
      "163/163 [==============================] - 4231s 26s/step - loss: 0.0062 - acc: 0.9919 - val_loss: 0.0364 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00059\n",
      "Epoch 31/100\n",
      "163/163 [==============================] - 4957s 30s/step - loss: 0.0077 - acc: 0.9893 - val_loss: 0.0386 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00059\n",
      "Epoch 32/100\n",
      "163/163 [==============================] - 4675s 29s/step - loss: 0.0081 - acc: 0.9887 - val_loss: 0.0291 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00059\n",
      "Epoch 33/100\n",
      "163/163 [==============================] - 3718s 23s/step - loss: 0.0077 - acc: 0.9891 - val_loss: 0.0169 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00059\n",
      "Epoch 34/100\n",
      "163/163 [==============================] - 3518s 22s/step - loss: 0.0078 - acc: 0.9889 - val_loss: 0.0267 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00059\n",
      "\n",
      "\n",
      "================================\n",
      "\n",
      "\n",
      "Loss: 0.07636952962527105\n",
      "Accuracy: 90.06 %\n",
      "\n",
      "\n",
      "================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = Conv2D(256, kernel_size=(9, 9), strides=(1, 1), activation='relu')(base_model.get_layer(name='block5_pool').output)\n",
    "\n",
    "x = Reshape((-1, 256))(output)\n",
    "capsule = Capsule(2, 16, 4, True)(x)\n",
    "output = Lambda(lambda z: K.sqrt(K.sum(K.square(z), 2)))(capsule)\n",
    "model = Model(inputs=input_image, outputs=output)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "lr=1e-4\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"weights.h5\", \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             save_weights_only=False, \n",
    "                             mode='min')\n",
    "\n",
    "early = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min', restore_best_weights=True)\n",
    "\n",
    "callback_list = [checkpoint, early]\n",
    "\n",
    "epochs=100\n",
    "\n",
    "model.compile(loss=margin_loss, optimizer=SGD(lr=lr, momentum=0.9), metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(train,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=val, \n",
    "                    validation_steps = len(val.classes)//val_batch,\n",
    "                    steps_per_epoch=len(train.classes)//train_batch,\n",
    "                    callbacks=callback_list)\n",
    "    \n",
    "loss, acc = model.evaluate_generator(test, len(test))\n",
    "\n",
    "print (\"\\n\\n================================\\n\\n\")\n",
    "print (\"Loss: {}\".format(loss))\n",
    "print (\"Accuracy: {0:.2f} %\".format(acc * 100))\n",
    "print (\"\\n\\n================================\\n\\n\")\n",
    "\n",
    "test.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO (Ethan planning to work on this sunday morning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] https://www.ibm.com/cloud/learn/convolutional-neural-networks\n",
    "\n",
    "[2] https://www.kaggle.com/madz2000/pneumonia-detection-using-cnn-92-6-accuracy\n",
    "\n",
    "[3] https://data.mendeley.com/datasets/rscbjbr9sj/2 (THIS IS THE DATASET)\n",
    "\n",
    "[4] https://www.kaggle.com/teyang/pneumonia-detection-resnets-pytorch\n",
    "\n",
    "[5] https://towardsdatascience.com/residual-blocks-building-blocks-of-resnet-fd90ca15d6ec\n",
    "\n",
    "[6] https://course19.fast.ai/videos/?lesson=1\n",
    "\n",
    "[7] Alber, M., Lapuschkin, S., Seegerer, P., Hägele, M., Schütt, K. T., Montavon, G., Samek, W., Müller, K. R., Dähne, S., & Kindermans, P. J. (2019). iNNvestigate neural networks! Journal of Machine Learning Research, 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
